<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-probability-conditional" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Conditional Probability and Independent Events</title>

	<objectives>
			<ul>
				<li>
					<p>
						Identify independent and dependent events
					</p>
				</li>
				<li>
					<p>
						Compute and interpret conditional probabilities
					</p>
				</li>
				<li>
					<p>
						Calculate probabilities using tree diagrams, including <q>Bayesian</q> problems.
					</p>
				</li>
			</ul>
	</objectives>
	<introduction>
		<p>
			In the previous section, we explored how calculating probabilities can become more complex when dealing with multiple events. In this section, we turn our attention to how the probability of an event can change when additional information is known. Sometimes, we calculate the probability of an event based solely on the overall sample space. Other times, we calculate the probability of an event given that another event has already occurred. Understanding which approach to use is essential for analyzing dependent and independent events.
		</p>
	</introduction>
	<subsection xml:id="sec_probability_conditional_independence">
		<title>Independence</title>
		<p>
			Sometimes knowledge about one event can change the probability of another event. When knowledge about one event happening or not happening changes the probability of another event happening, the events are called <term>dependent</term>. When knowledge about one event makes no difference in the probability of another event happening, the events are called <term>independent</term>.
		</p>
		<definition xml:id="def_independent">
			<idx><h>independent events</h></idx>
			<idx><h>probability</h><h>independence</h></idx>
			<statement>
				<p>
					Two events, <m>A</m> and <m>B</m>, are called <term>independent</term> if the occurrence of <m>A</m> has no influence on the probability of <m>B</m>.
				</p>
			</statement>
		</definition>
		<p>
			Coin flips and die rolls are common examples of independent events <mdash/> flipping heads does not change the probability of flipping heads the next time, nor does rolling a six change the probability that the next roll will be a six. Here is another example illustrating the difference between independent and dependent events.
			<ul>
				<li>
					<p>
						The events <q>it is raining in New York City</q> and <q>there is a traffic jam in Los Angeles</q> are <alert>independent</alert>.
					</p>
				</li>
				<li>
					<p>
						The events <q>it is raining in New York City</q> and <q>there is a traffic jam in New York City</q> could be <alert>dependent</alert>.
					</p>
				</li>
			</ul>
			Why might rain and a traffic jam be <em>dependent</em>? Because heavy rain can make driving more difficult, increasing the likelihood of slowdowns or accidents that lead to traffic jams! The following example gives more illustrations of dependent and independent events.
		</p>
		<example xml:id="ex_conditional_independent-or-dependent">
			<!-- <title>Determining if Events are Independent or Dependent</title> -->
			<statement>
				<p>
					Determine if the pairs of events <m>A</m> and <m>B</m> described below are independent or dependent.
				  <ol marker="a.">
				  	<li>
							<p>
								A coin is flipped three times and <m>A =</m> <q>the first flip is a heads</q> while <m>B =</m> <q>the last flip is a heads.</q>
							</p>
						</li>
				  	<li>
							<p>
								A coin is flipped three times and <m>A =</m> <q>the first flip is a heads</q> while <m>B =</m> <q>all flips are heads.</q>
							</p>
						</li>
				  	<li>
							<p>
								An jar contains three marbles: 2 red and 1 white. Two marbles are drawn, with replacement. <m>A =</m> <q>the first marble is white</q> while <m>B =</m> <q>the second marble is white.</q>
							</p>
						</li>
				  	<li>
							<p>
								An jar contains three marbles: 2 red and 1 white. Two marbles are drawn, without replacement. <m>A =</m> <q>the first marble is white</q> while <m>B =</m> <q>the second marble is white.</q>
							</p>
						</li>
				  </ol>
				</p>
			</statement>
			<solution>
				<p>
					<ol marker="a.">
						<li>
							<p>
								Does knowing if the first flip was a heads or tails change the probability that the third flip will be a heads? Coins do not have memories. Anything we know about the first flip has no effect on what happens on the second flip, so <m>A</m> and <m>B</m> are <term>independent</term>.
							</p>
						</li>
						<li>
							<p>
								This experiment is different from the previous one. Knowing that the first flip came up a heads does have an effect on whether all three flips come up heads. After all, if <m>A</m> did not happen, then <m>B</m> can not possibly happen either. Therefore, <m>A</m> and <m>B</m> are <term>dependent</term>.
							</p>
						</li>
						<li>
							<p>
								Since we are replacing the marbles after we draw them, the probability of getting a red on the first draw and on the second draw are the same: <m>\frac{2}{3}</m>. What happens on the first draw does not effect the probability of getting a red on the second draw. Because of this, <m>A</m> and <m>B</m> are <term>independent</term>.
							</p>
						</li>
						<li>
							<p>
								In our final question, we are again drawing marbles, but this time what happens on the first draw does make a difference. Since we do not replace the marbles we draw, if <m>A</m> does not happen (we draw red), there are two marbles left: 1 red and 1 white. So <m>P(B) = \frac{1}{2}</m>. However, if <m>A</m> does happen (we draw a white), then there are two marbles left, both of which are red. So <m>P(B) = 0</m>. Since <m>P(B)</m> changes depending on whether <m>A</m> happens or not, <m>A</m> and <m>B</m> are <term>dependent</term>.
							</p>
						</li>
					</ol>
				</p>
			</solution>
		</example>
	</subsection>
	<subsection xml:id="sec_probability_conditional_formula">
		<title>Conditional Probability</title>
		<p>
			As we saw above, the probability of one event can change depending on the occurrence of another. Because these probabilities can be different, we need a way to denote the probability of one event given than another has occurred. This is called the <term>conditional probability</term> of the first event, given that the second event happens. The formal definition is given below.
		</p>
		<definition xml:id="def_conditional-probability">
			<idx>conditional probability</idx>
			<idx><h>probability</h><h>conditional</h></idx>
			<statement>
				<p>
					The <term>conditional probability</term> of <m>A</m> given <m>B</m> is the probability of event <m>A</m> given that event <m>B</m> has occurred. Symbolically, this is written as <m>P(A\mid B)</m>.
				</p>
			</statement>
		</definition>
		<p>
			We read <m>P(A\mid B)</m> as <q>the probability of <m>A</m> given <m>B</m>.</q> This simply means the probability of <m>A</m> with the extra information that <m>B</m> has happened. In <xref ref="ex_conditional_independent-or-dependent"/> we saw several pairs <m>A</m> and <m>B</m> of events for which having the information that <m>B</m> happened changed the probability of <m>A</m>. These dependent events provide good examples for computing conditional probabilities.
		</p>
		<example xml:id="ex_conditional_compute">
			<title>Computing Conditional Probabilities from Outcomes</title>
			<statement>
				<p>
					A coin is flipped three times. Events <m>A</m> and <m>B</m> are defined as follows.
				  <ul cols="2">
				    <li><p><m>A</m>: the first flip is a heads</p></li>
				    <li><p><m>B</m>: all three flips are heads</p></li>
				  </ul>
				</p>
				<p>
					Find the sample space for this experiment, the outcomes in <m>A</m>, and the outcomes in <m>B</m>. Use this information to find <m>P(A)</m> and <m>P(A\mid B)</m>.
				</p>
			</statement>
			<solution>
				<p>
					Since the experiment involves flipping a coin three times, a sample outcome would be <m>HHT</m>, representing the first flip coming up heads, the second heads, and the last tails. The set of all outcomes is therefore:
				  <me>
						S = \lbrace HHH, HHT, HTH, HTT, THH, THT, TTH, TTT \rbrace
					</me>.
				</p>
				<p>
					The first event of interest, <m>A</m>, consists of all of the outcomes above resulting in a heads on the first flip. This is:
				  <me>
						A = \lbrace HHH, HHT, HTH, HTT \rbrace
					</me>.
				  We can therefore conclude that
				  <me>
						P(A) = \frac{n(A)}{n(S)} = \frac{4}{8} = \frac{1}{2} = 0.50
					</me>.
				</p>
				<p>
					But what about <m>B</m>? The event <m>B</m> is:
					<me>
						B = \lbrace HHH \rbrace
					</me>.
					If we know that <m>B</m> has happened, then we automatically know that <m>A</m> has happened as well.  This is because if all three flips are heads, the first one must have been a heads (<m>B</m> is a subset of <m>A</m>). Therefore, 
					<me>
						P(A\mid B) = 1
					</me>.
				</p>
				<p>
					Note that <m>P(A\mid B)</m> and <m>P(A)</m> are different! This is equivalent to saying that <m>A</m> and <m>B</m> are dependent
				</p>
			</solution>
		</example>
		</subsection>

</section>